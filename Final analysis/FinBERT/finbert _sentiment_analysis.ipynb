{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72e597f5",
   "metadata": {},
   "source": [
    "# Finbert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6826a1",
   "metadata": {},
   "source": [
    "#### Importing model - [FinBert](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3910214)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd84d1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in d:\\users\\burts\\anaconda3\\lib\\site-packages (4.39.1)\n",
      "Requirement already satisfied: filelock in d:\\users\\burts\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in d:\\users\\burts\\anaconda3\\lib\\site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\users\\burts\\anaconda3\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\users\\burts\\anaconda3\\lib\\site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\users\\burts\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\users\\burts\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in d:\\users\\burts\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in d:\\users\\burts\\anaconda3\\lib\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in d:\\users\\burts\\anaconda3\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\users\\burts\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\users\\burts\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\users\\burts\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
      "Requirement already satisfied: colorama in d:\\users\\burts\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\users\\burts\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\users\\burts\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\users\\burts\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\users\\burts\\anaconda3\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: torch in d:\\users\\burts\\anaconda3\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: torchvision in d:\\users\\burts\\anaconda3\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: torchaudio in d:\\users\\burts\\anaconda3\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: filelock in d:\\users\\burts\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\users\\burts\\anaconda3\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in d:\\users\\burts\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in d:\\users\\burts\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in d:\\users\\burts\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in d:\\users\\burts\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: numpy in d:\\users\\burts\\anaconda3\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\users\\burts\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\users\\burts\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\users\\burts\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\burts\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.39.1\n",
      "2.2.1+cpu\n"
     ]
    }
   ],
   "source": [
    "# Import all the necessary packages.\n",
    "!pip install transformers\n",
    "!pip install torch torchvision torchaudio\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import transformers\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "print(transformers.__version__)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f394154",
   "metadata": {},
   "source": [
    "#### Importing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99c14082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data set. We will use the less normalised Vader data set which has been copied into a new .csv. \n",
    "speech_finbert = pd.read_csv('speech_bert_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110ed8fc",
   "metadata": {},
   "source": [
    "Unlike with previous models, FinBert was trained on Financial Corpora which include:\n",
    "\n",
    "- Corporate Reports 10-K & 10-Q: 2.5B tokens \n",
    " \n",
    "- Earnings Call Transcripts: 1.3B tokens \n",
    " \n",
    "- Analyst Reports: 1.1B tokens \n",
    "\n",
    "This means that it will be run on the un normalised \"text\" column to ensure accuracy is maintained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08656c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>is_gov</th>\n",
       "      <th>text</th>\n",
       "      <th>Body</th>\n",
       "      <th>central_bank</th>\n",
       "      <th>year</th>\n",
       "      <th>language</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r980915a_BOE</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>1998-09-15</td>\n",
       "      <td>Speech</td>\n",
       "      <td>George</td>\n",
       "      <td>False</td>\n",
       "      <td>Thank you, Chairman. I'm actually very pleased...</td>\n",
       "      <td>BOE</td>\n",
       "      <td>Bank of England</td>\n",
       "      <td>1998</td>\n",
       "      <td>en</td>\n",
       "      <td>thank chairman actually pleased opportunity re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r981021b_BOE</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>1998-10-21</td>\n",
       "      <td>Britain in Europe</td>\n",
       "      <td>George</td>\n",
       "      <td>False</td>\n",
       "      <td>It's a great pleasure to be here in the beauti...</td>\n",
       "      <td>BOE</td>\n",
       "      <td>Bank of England</td>\n",
       "      <td>1998</td>\n",
       "      <td>en</td>\n",
       "      <td>great pleasure beautiful city bruges honoured ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r981021a_BOE</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>1998-10-21</td>\n",
       "      <td>Impact of the recent turbulence in internation...</td>\n",
       "      <td>King</td>\n",
       "      <td>True</td>\n",
       "      <td>Few industries have suffered more from volatil...</td>\n",
       "      <td>BOE</td>\n",
       "      <td>Bank of England</td>\n",
       "      <td>1998</td>\n",
       "      <td>en</td>\n",
       "      <td>industries suffered volatility british economy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r981101a_BOE</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>1998-11-01</td>\n",
       "      <td>Economic policy, with and without forecasts</td>\n",
       "      <td>Budd</td>\n",
       "      <td>False</td>\n",
       "      <td>My topic this evening is the use of forecasts ...</td>\n",
       "      <td>BOE</td>\n",
       "      <td>Bank of England</td>\n",
       "      <td>1998</td>\n",
       "      <td>en</td>\n",
       "      <td>topic evening use forecasts economic general u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r981101b_BOE</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>1998-11-01</td>\n",
       "      <td>Inflation targeting in practice: the UK experi...</td>\n",
       "      <td>Vickers</td>\n",
       "      <td>False</td>\n",
       "      <td>Six years ago this week, sterling left the exc...</td>\n",
       "      <td>BOE</td>\n",
       "      <td>Bank of England</td>\n",
       "      <td>1998</td>\n",
       "      <td>en</td>\n",
       "      <td>six years ago week sterling left exchange rate...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      reference         country        date  \\\n",
       "0  r980915a_BOE  United Kingdom  1998-09-15   \n",
       "1  r981021b_BOE  United Kingdom  1998-10-21   \n",
       "2  r981021a_BOE  United Kingdom  1998-10-21   \n",
       "3  r981101a_BOE  United Kingdom  1998-11-01   \n",
       "4  r981101b_BOE  United Kingdom  1998-11-01   \n",
       "\n",
       "                                               title   author  is_gov  \\\n",
       "0                                             Speech   George   False   \n",
       "1                                  Britain in Europe   George   False   \n",
       "2  Impact of the recent turbulence in internation...     King    True   \n",
       "3        Economic policy, with and without forecasts     Budd   False   \n",
       "4  Inflation targeting in practice: the UK experi...  Vickers   False   \n",
       "\n",
       "                                                text Body     central_bank  \\\n",
       "0  Thank you, Chairman. I'm actually very pleased...  BOE  Bank of England   \n",
       "1  It's a great pleasure to be here in the beauti...  BOE  Bank of England   \n",
       "2  Few industries have suffered more from volatil...  BOE  Bank of England   \n",
       "3  My topic this evening is the use of forecasts ...  BOE  Bank of England   \n",
       "4  Six years ago this week, sterling left the exc...  BOE  Bank of England   \n",
       "\n",
       "   year language                                         clean_text  \n",
       "0  1998       en  thank chairman actually pleased opportunity re...  \n",
       "1  1998       en  great pleasure beautiful city bruges honoured ...  \n",
       "2  1998       en  industries suffered volatility british economy...  \n",
       "3  1998       en  topic evening use forecasts economic general u...  \n",
       "4  1998       en  six years ago week sterling left exchange rate...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech_finbert.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab3d406",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c9c629",
   "metadata": {},
   "source": [
    "#### Text Chunking to Handle BERT Token Limit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518fb783",
   "metadata": {},
   "source": [
    "BERT models have a token limit of 512. We will write a function to chunk the text appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "946fcfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def chunk_text(text, max_length=510):  # Reserve 2 tokens for special tokens\n",
    "    \"\"\"\n",
    "    Splits text into BERT-compatible chunks.\n",
    "    \"\"\"\n",
    "    # Tokenize the text into sentences.\n",
    "    sentences = sent_tokenize(text)\n",
    "    current_chunk = []\n",
    "    chunks = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        if len(current_chunk) + len(sentence.split()) <= max_length:\n",
    "            current_chunk.extend(sentence.split())\n",
    "        else:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = sentence.split()\n",
    "    \n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0616d8d4",
   "metadata": {},
   "source": [
    "#### Setting Up FinBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c30cbc",
   "metadata": {},
   "source": [
    "FinBERT is a pre-trained model by Hugging Face, tailored for financial sentiment analysis. We'll load the model and tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fdf8020",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
    "model = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809d4df7",
   "metadata": {},
   "source": [
    "#### Applying FinBERT to Chunked Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa529062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the analyse_sentiment function\n",
    "def analyse_sentiment(text):\n",
    "    model.eval()\n",
    "    chunks = chunk_text(text)\n",
    "    sentiments = []\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        inputs = tokenizer(chunk, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        sentiments.append(predictions.detach().numpy()[0])\n",
    "    \n",
    "    avg_sentiments = np.mean(sentiments, axis=0)\n",
    "    sentiment_series = pd.Series(avg_sentiments, index=['neutral', 'positive', 'negative'])\n",
    "    polarity_score = sentiment_series['positive'] - sentiment_series['negative']\n",
    "    sentiment_series['polarity_score'] = polarity_score\n",
    "    \n",
    "    return sentiment_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fb6873",
   "metadata": {},
   "source": [
    "The Sentiment Analysis function does the following things:\n",
    "\n",
    "Chunking the Text: \n",
    "- Divides the input text into smaller chunks to fit the model's maximum input size.\n",
    "\n",
    "Processing Each Chunk:\n",
    "- Tokenisation: Converts text chunks into a format suitable for the model using the tokeniser.\n",
    "- Model Inference: Passes tokenized input through the model to obtain sentiment scores.\n",
    "- Softmax Application: Converts raw scores into probabilities using softmax function.\n",
    "- Aggregating Sentiment Scores: Averages sentiment probabilities across all chunks to represent overall sentiment.\n",
    "\n",
    "Calculating Polarity Score: \n",
    "- Computes a single polarity score as the difference between positive and negative sentiment probabilities, providing a summary sentiment metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b30c70db-ecff-4b9d-b6bc-8bef392138b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping found: {0: 'Neutral', 1: 'Positive', 2: 'Negative'}\n"
     ]
    }
   ],
   "source": [
    "# Confirm the order of sentiment output is 'neutral', 'positive', 'neegative'. \n",
    "\n",
    "#Option 1: Inspect model configuration\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone')\n",
    "\n",
    "# Attempt to find label mappings\n",
    "if model.config.id2label:\n",
    "    print(\"Label mapping found:\", model.config.id2label)\n",
    "else:\n",
    "    print(\"Label mapping not explicitly defined in this model's configuration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e05cbe6",
   "metadata": {},
   "source": [
    "> [Here is official documentation suggesting the order of the outputs are 0:'neutral', 1:'positive',2:'negative' as well](https://github.com/yya518/FinBERT) As such we will define our outputs accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5301b5bf-7d96-4ee4-8ba7-91fbf0c7b613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.2756287e-08 1.0000000e+00 2.2150109e-08]\n"
     ]
    }
   ],
   "source": [
    "# Option 2a: Test out a sentence to sense check our understanding of order (positive sentence)\n",
    "\n",
    "def analyse_sentiment_test(text):\n",
    "    model.eval()\n",
    "    # Directly tokenize the text without chunking\n",
    "    inputs = tokenizer(text, add_special_tokens=True, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    outputs = model(**inputs)\n",
    "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    sentiments = predictions.detach().numpy()\n",
    "    \n",
    "    # Calculate the average of the sentiments directly from the predictions\n",
    "    avg_sentiments = np.mean(sentiments, axis=0)\n",
    "    \n",
    "    # Print the average sentiments\n",
    "    print(avg_sentiments)\n",
    "\n",
    "# Specify the text you want to analyze\n",
    "text = \"The Bank of England are optimistic about the UK's economic outlook.\"\n",
    "\n",
    "# Call the analyse_sentiment function with the specified text\n",
    "analyse_sentiment_test(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c113caa7-f90a-4d51-b9ab-cfaa4fcc4cc8",
   "metadata": {},
   "source": [
    "The output shows 0.0000032756411% probability of neutrality, 100% probability of positivity, and 0.0000022150193% probability of negativity. This is in line with our understanding of the order of sentiment. Let's try a clearly negative statement also, and analyse the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a074f95-4a4b-498f-9e12-84391e846540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.5969535e-07 7.0430048e-09 9.9999976e-01]\n"
     ]
    }
   ],
   "source": [
    "# Option 2b: Test out a sentence to sense check our understanding of order (negative sentence)\n",
    "\n",
    "def analyse_sentiment_test(text):\n",
    "    model.eval()\n",
    "    # Directly tokenize the text without chunking\n",
    "    inputs = tokenizer(text, add_special_tokens=True, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    outputs = model(**inputs)\n",
    "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    sentiments = predictions.detach().numpy()\n",
    "    \n",
    "    # Calculate the average of the sentiments directly from the predictions\n",
    "    avg_sentiments = np.mean(sentiments, axis=0)\n",
    "    \n",
    "    # Print the average sentiments\n",
    "    print(avg_sentiments)\n",
    "\n",
    "# Specify the text you want to analyze\n",
    "text = \"The Bank of England are worried about the UK's economic outlook.\"\n",
    "\n",
    "# Call the analyse_sentiment function with the specified text\n",
    "analyse_sentiment_test(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a5ded6-d324-495b-9cd3-de1d734db040",
   "metadata": {},
   "source": [
    "The output shows 0.00002597%. probability of neutrality, 0.0000007043%. probability of positivity, and 99.999976% probability of negativity. This is in line with our understanding of the order of sentiment. \n",
    "\n",
    "Through the model's configuration and testing of sentences, we are confident that the order of sentiment output is neutral, positive, and negative. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee87e576",
   "metadata": {},
   "source": [
    "# Analysing Sentiments of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d2a7c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As it's a long calcualtion a progress bar is a useful measure. \n",
    "from tqdm import tqdm\n",
    "\n",
    "# Enable tqdm progress bar for pandas apply\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd604744",
   "metadata": {},
   "source": [
    "Now we have \"analyse_sentiment\" that returns the sentiment scores in the form [neutral, positive, negative] for a given text, we can loop through each text, apply analyse_sentiment, then calculate the polarity score using calculate_polarity. Finally, we'll store these polarity scores in a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88ba14ae-4115-47da-be4f-75fa297dbd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the analyse_sentiment function to the first 10 entries of the dataset\n",
    "# finbert_polarity = speech_finbert['text'].head(10).progress_apply(analyse_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "523e534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanding the results into the original DataFrame\n",
    "# speech_finbert[['neutral', 'positive', 'negative', 'polarity_score']] = finbert_polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75618bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# speech_finbert.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c6649e",
   "metadata": {},
   "source": [
    "Now we create a function that calculates the polarity score based on the sentiment analysis results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7ef82e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1209 [00:44<5:00:46, 14.96s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Apply the analyse_sentiment function to the all  entries of the dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m finbert_polarity \u001b[38;5;241m=\u001b[39m speech_finbert[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mprogress_apply(analyse_sentiment)\n",
      "File \u001b[1;32mD:\\Users\\burts\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:805\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[1;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(df, df_function)(wrapper, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    806\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    807\u001b[0m     t\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mD:\\Users\\burts\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\u001b[38;5;28mself\u001b[39m, func, convert_dtype, args, kwargs)\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32mD:\\Users\\burts\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32mD:\\Users\\burts\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1173\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1174\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmap_infer(\n\u001b[0;32m   1175\u001b[0m             values,\n\u001b[0;32m   1176\u001b[0m             f,\n\u001b[0;32m   1177\u001b[0m             convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype,\n\u001b[0;32m   1178\u001b[0m         )\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1181\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1182\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mD:\\Users\\burts\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\Users\\burts\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:800\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    795\u001b[0m     \u001b[38;5;66;03m# update tbar correctly\u001b[39;00m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[0;32m    797\u001b[0m     \u001b[38;5;66;03m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[0;32m    798\u001b[0m     \u001b[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[0;32m    799\u001b[0m     t\u001b[38;5;241m.\u001b[39mupdate(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m<\u001b[39m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 800\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[6], line 9\u001b[0m, in \u001b[0;36manalyse_sentiment\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks:\n\u001b[0;32m      8\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m tokenizer(chunk, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m     10\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(outputs\u001b[38;5;241m.\u001b[39mlogits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     11\u001b[0m     sentiments\u001b[38;5;241m.\u001b[39mappend(predictions\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mD:\\Users\\burts\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Users\\burts\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Users\\burts\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1564\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1560\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1561\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1562\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1564\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert(\n\u001b[0;32m   1565\u001b[0m     input_ids,\n\u001b[0;32m   1566\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   1567\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[0;32m   1568\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   1569\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m   1570\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m   1571\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1572\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1573\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1574\u001b[0m )\n\u001b[0;32m   1576\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   1578\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[1;32mD:\\Users\\burts\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Users\\burts\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Users\\burts\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1013\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1004\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   1006\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m   1007\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1008\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1011\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   1012\u001b[0m )\n\u001b[1;32m-> 1013\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[0;32m   1014\u001b[0m     embedding_output,\n\u001b[0;32m   1015\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   1016\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m   1017\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m   1018\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_extended_attention_mask,\n\u001b[0;32m   1019\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m   1020\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m   1021\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1022\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1023\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1024\u001b[0m )\n\u001b[0;32m   1025\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1026\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Users\\burts\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Users\\burts\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Users\\burts\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:607\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    596\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    597\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    598\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    604\u001b[0m         output_attentions,\n\u001b[0;32m    605\u001b[0m     )\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 607\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[0;32m    608\u001b[0m         hidden_states,\n\u001b[0;32m    609\u001b[0m         attention_mask,\n\u001b[0;32m    610\u001b[0m         layer_head_mask,\n\u001b[0;32m    611\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    612\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    613\u001b[0m         past_key_value,\n\u001b[0;32m    614\u001b[0m         output_attentions,\n\u001b[0;32m    615\u001b[0m     )\n\u001b[0;32m    617\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mD:\\Users\\burts\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Users\\burts\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Users\\burts\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:539\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    536\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    537\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 539\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m apply_chunking_to_forward(\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeed_forward_chunk, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_size_feed_forward, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len_dim, attention_output\n\u001b[0;32m    541\u001b[0m )\n\u001b[0;32m    542\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[0;32m    544\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Users\\burts\\anaconda3\\Lib\\site-packages\\transformers\\pytorch_utils.py:237\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m forward_fn(\u001b[38;5;241m*\u001b[39minput_tensors)\n",
      "File \u001b[1;32mD:\\Users\\burts\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:552\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m    551\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[1;32m--> 552\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32mD:\\Users\\burts\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Users\\burts\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Users\\burts\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:464\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 464\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[0;32m    465\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m    466\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n",
      "File \u001b[1;32mD:\\Users\\burts\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Users\\burts\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Users\\burts\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Apply the analyse_sentiment function to the all  entries of the dataset\n",
    "finbert_polarity = speech_finbert['text'].progress_apply(analyse_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfaeb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanding the results into the original DataFrame\n",
    "speech_finbert[['neutral', 'positive', 'negative', 'polarity_score']] = finbert_polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd10f1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "speech_finbert.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154b9b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the finbert_compound to vader_polarity for consistency with other models. \n",
    "speech_finbert = speech_finbert.rename(columns={'polarity_score': 'finbert_polarity'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d0d905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the neu, pos, neg columns for consistency with other models. \n",
    "speech_finbert = speech_finbert.rename(columns={'neutral': 'finbert_neutral', 'positive': 'finbert_positive', 'negative': 'finbert_negative',  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f83a547-bb98-4ef3-90e2-4d722d5063f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_finbert.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25268927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export DataFrame to CSV\n",
    "# speech_finbert.to_csv('finbert_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdb685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram for speech_vader_compound\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(\n",
    "    speech_finbert['finbert_polarity'],\n",
    "    bins=34,\n",
    "    alpha=0.7,\n",
    "    color='blue',\n",
    "    label='Speech Fibert Compound scores'\n",
    ")\n",
    "plt.title('Finbert Sentiment Scorre Distribution)\n",
    "plt.xlabel('finbert_polarity')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "3e5140d1",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3707048",
   "metadata": {},
   "source": [
    "- Finbert shows a strong and healthy curve around the expected netural of a central bank's communication style. As such this will be our model choicie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c079c0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_finbert['finbert_polarity'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569b5ec8",
   "metadata": {},
   "source": [
    "- Mean: The average sentiment score is very close to zero (0.005142), indicating that overall sentiment across all speeches is almost neutral.\n",
    "- Standard Deviation: A relatively high standard deviation (0.234896) suggests there's considerable variability in sentiment scores.\n",
    "- Minimum: The most negative sentiment score is quite low (-0.805046), showing that there have been instances of strongly negative sentiment.\n",
    "- 25th Percentile: 25% of the scores are lower than -0.105807, which could be considered mildly negative.\n",
    "- Median (50th Percentile): The median sentiment score is slightly negative (-0.004519), reinforcing the mean's indication of a general tilt towards neutral sentiment.\n",
    "- 75th Percentile: 75% of the scores are below 0.093910, indicating that more positive sentiments are not as extreme as the negative ones.\n",
    "- Maximum: The most positive sentiment score is very high (0.938213), showing that there have also been instances of strongly positive sentiment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
